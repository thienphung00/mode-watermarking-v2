# GPU Worker Deployment
# Requires GPU node pool with NVIDIA drivers
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gpu-worker
  namespace: watermarking
  labels:
    app.kubernetes.io/name: watermarking
    app.kubernetes.io/component: gpu-worker
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: watermarking
      app.kubernetes.io/component: gpu-worker
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        app.kubernetes.io/name: watermarking
        app.kubernetes.io/component: gpu-worker
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: watermarking-worker
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      # Tolerate GPU node taints
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      # Select GPU nodes
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-tesla-t4
      containers:
        - name: worker
          image: watermarking-worker:latest
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          envFrom:
            - configMapRef:
                name: watermarking-config
          env:
            # Override inference mode for worker
            - name: INFERENCE_MODE
              value: "local"
          resources:
            requests:
              cpu: "2000m"
              memory: "8Gi"
              nvidia.com/gpu: "1"
            limits:
              cpu: "4000m"
              memory: "16Gi"
              nvidia.com/gpu: "1"
          livenessProbe:
            httpGet:
              path: /v1/health
              port: http
            initialDelaySeconds: 300  # 5 min for model loading
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /v1/ready
              port: http
            initialDelaySeconds: 300
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          volumeMounts:
            - name: artifacts
              mountPath: /app/artifacts
              readOnly: true
            - name: huggingface-cache
              mountPath: /home/worker/.cache/huggingface
      volumes:
        - name: artifacts
          persistentVolumeClaim:
            claimName: artifacts-pvc
        - name: huggingface-cache
          persistentVolumeClaim:
            claimName: huggingface-cache-pvc
---
# GPU Worker Service
apiVersion: v1
kind: Service
metadata:
  name: gpu-worker
  namespace: watermarking
  labels:
    app.kubernetes.io/name: watermarking
    app.kubernetes.io/component: gpu-worker
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 8080
      targetPort: http
      protocol: TCP
  selector:
    app.kubernetes.io/name: watermarking
    app.kubernetes.io/component: gpu-worker
---
# Service Account
apiVersion: v1
kind: ServiceAccount
metadata:
  name: watermarking-worker
  namespace: watermarking
  labels:
    app.kubernetes.io/name: watermarking
    app.kubernetes.io/component: gpu-worker
---
# Horizontal Pod Autoscaler for GPU workers
# Uses custom metrics from Prometheus
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: gpu-worker-hpa
  namespace: watermarking
  labels:
    app.kubernetes.io/name: watermarking
    app.kubernetes.io/component: gpu-worker
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: gpu-worker
  minReplicas: 1
  maxReplicas: 5
  metrics:
    # Scale based on GPU memory utilization
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 60
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 600  # 10 min cooldown (GPU expensive)
      policies:
        - type: Pods
          value: 1
          periodSeconds: 120  # Remove 1 pod per 2 minutes max
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
        - type: Pods
          value: 2
          periodSeconds: 60
---
# Pod Disruption Budget for GPU workers
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: gpu-worker-pdb
  namespace: watermarking
  labels:
    app.kubernetes.io/name: watermarking
    app.kubernetes.io/component: gpu-worker
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: watermarking
      app.kubernetes.io/component: gpu-worker

